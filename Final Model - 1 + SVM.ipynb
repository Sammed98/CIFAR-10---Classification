{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rithwik/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    "X_test = (X_test - 127.5) / 127.5\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed= 100\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " \n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003       \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 1.6404 - acc: 0.4637 - val_loss: 1.1433 - val_acc: 0.6050\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60500, saving model to weights-improvement-01-0.60.hdf5\n",
      "Epoch 2/125\n",
      "50000/50000 [==============================] - 126s 3ms/step - loss: 1.0467 - acc: 0.6532 - val_loss: 0.9932 - val_acc: 0.6789\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60500 to 0.67890, saving model to weights-improvement-02-0.68.hdf5\n",
      "Epoch 3/125\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.8862 - acc: 0.7171 - val_loss: 0.8256 - val_acc: 0.7412\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67890 to 0.74120, saving model to weights-improvement-03-0.74.hdf5\n",
      "Epoch 4/125\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.7985 - acc: 0.7520 - val_loss: 0.7757 - val_acc: 0.7694\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.74120 to 0.76940, saving model to weights-improvement-04-0.77.hdf5\n",
      "Epoch 5/125\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.7445 - acc: 0.7746 - val_loss: 0.7500 - val_acc: 0.7743\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.76940 to 0.77430, saving model to weights-improvement-05-0.77.hdf5\n",
      "Epoch 6/125\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.7056 - acc: 0.7902 - val_loss: 0.6885 - val_acc: 0.7989\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.77430 to 0.79890, saving model to weights-improvement-06-0.80.hdf5\n",
      "Epoch 7/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.6721 - acc: 0.8036 - val_loss: 0.7068 - val_acc: 0.7954\n",
      "\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 8/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.6482 - acc: 0.8166 - val_loss: 0.6927 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.79890 to 0.80450, saving model to weights-improvement-08-0.80.hdf5\n",
      "Epoch 9/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.6278 - acc: 0.8255 - val_loss: 0.7303 - val_acc: 0.7913\n",
      "\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 10/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.6080 - acc: 0.8320 - val_loss: 0.7160 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.80450 to 0.80550, saving model to weights-improvement-10-0.81.hdf5\n",
      "Epoch 11/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.5897 - acc: 0.8419 - val_loss: 0.6610 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.80550 to 0.82430, saving model to weights-improvement-11-0.82.hdf5\n",
      "Epoch 12/125\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.5759 - acc: 0.8471 - val_loss: 0.6686 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/125\n",
      "50000/50000 [==============================] - 126s 3ms/step - loss: 0.5615 - acc: 0.8552 - val_loss: 0.6715 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.82430 to 0.82460, saving model to weights-improvement-13-0.82.hdf5\n",
      "Epoch 14/125\n",
      "50000/50000 [==============================] - 127s 3ms/step - loss: 0.5536 - acc: 0.8575 - val_loss: 0.7135 - val_acc: 0.8209\n",
      "\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 15/125\n",
      "50000/50000 [==============================] - 124s 2ms/step - loss: 0.5451 - acc: 0.8625 - val_loss: 0.6725 - val_acc: 0.8280\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.82460 to 0.82800, saving model to weights-improvement-15-0.83.hdf5\n",
      "Epoch 16/125\n",
      "50000/50000 [==============================] - 125s 3ms/step - loss: 0.5352 - acc: 0.8663 - val_loss: 0.6901 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.5242 - acc: 0.8716 - val_loss: 0.6697 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.82800 to 0.83230, saving model to weights-improvement-17-0.83.hdf5\n",
      "Epoch 18/125\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.5191 - acc: 0.8760 - val_loss: 0.6799 - val_acc: 0.8245\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.5153 - acc: 0.8766 - val_loss: 0.6808 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.83230 to 0.83690, saving model to weights-improvement-19-0.84.hdf5\n",
      "Epoch 20/125\n",
      "50000/50000 [==============================] - 121s 2ms/step - loss: 0.5091 - acc: 0.8804 - val_loss: 0.6608 - val_acc: 0.8409\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.83690 to 0.84090, saving model to weights-improvement-20-0.84.hdf5\n",
      "Epoch 21/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.5084 - acc: 0.8810 - val_loss: 0.6629 - val_acc: 0.8401\n",
      "\n",
      "Epoch 00021: val_acc did not improve\n",
      "Epoch 22/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.5016 - acc: 0.8858 - val_loss: 0.7010 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/125\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.4982 - acc: 0.8873 - val_loss: 0.6570 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.84090 to 0.84400, saving model to weights-improvement-23-0.84.hdf5\n",
      "Epoch 24/125\n",
      "50000/50000 [==============================] - 119s 2ms/step - loss: 0.4954 - acc: 0.8878 - val_loss: 0.6758 - val_acc: 0.8362\n",
      "\n",
      "Epoch 00024: val_acc did not improve\n",
      "Epoch 25/125\n",
      "50000/50000 [==============================] - 120s 2ms/step - loss: 0.4880 - acc: 0.8928 - val_loss: 0.6801 - val_acc: 0.8449\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.84400 to 0.84490, saving model to weights-improvement-25-0.84.hdf5\n",
      "Epoch 26/125\n",
      "50000/50000 [==============================] - 125s 3ms/step - loss: 0.4829 - acc: 0.8949 - val_loss: 0.6958 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/125\n",
      "50000/50000 [==============================] - 123s 2ms/step - loss: 0.4811 - acc: 0.8936 - val_loss: 0.6845 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/125\n",
      "50000/50000 [==============================] - 117s 2ms/step - loss: 0.4787 - acc: 0.8981 - val_loss: 0.7272 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/125\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 0.4751 - acc: 0.8987 - val_loss: 0.7244 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/125\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 0.4749 - acc: 0.8985 - val_loss: 0.6985 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/125\n",
      "50000/50000 [==============================] - 114s 2ms/step - loss: 0.4710 - acc: 0.9000 - val_loss: 0.7317 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/125\n",
      "50000/50000 [==============================] - 122s 2ms/step - loss: 0.4703 - acc: 0.9023 - val_loss: 0.6849 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00032: val_acc did not improve\n",
      "Epoch 33/125\n",
      "50000/50000 [==============================] - 124s 2ms/step - loss: 0.4691 - acc: 0.9027 - val_loss: 0.6795 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.84490 to 0.84550, saving model to weights-improvement-33-0.85.hdf5\n",
      "Epoch 34/125\n",
      " 4288/50000 [=>............................] - ETA: 1:44 - loss: 0.4455 - acc: 0.9118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(X_test,y_test),callbacks=[LearningRateScheduler(lr_schedule),checkpoint])\n",
    "#save to disk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/home/rithwik/Desktop/inter iit/Star Cluster/weights-improvement-33-0.85.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[883  14  14   5  15   1   3  10  35  20]\n",
      " [  7 944   0   2   2   1   0   0   7  37]\n",
      " [ 53   5 744  26  84  20  28  28   6   6]\n",
      " [ 21   6  44 621  66 126  39  52  11  14]\n",
      " [  7   4  15   9 890  12   6  51   6   0]\n",
      " [ 12   7  30  87  37 749  12  57   1   8]\n",
      " [  8   5  23  28  42   9 873   7   3   2]\n",
      " [  6   1   5  11  22  13   2 938   0   2]\n",
      " [ 34  21   3   2   3   1   3   4 914  15]\n",
      " [ 19  56   1   4   1   0   1   5  14 899]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_hat = model.predict(X_test)\n",
    "y_pred = [np.argmax(y_hat[i]) for i in range(len(y_hat))]\n",
    "y_true = [np.argmax(y_test[i]) for i in range(len(y_test))]\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      1000\n",
      "           1       0.89      0.94      0.92      1000\n",
      "           2       0.85      0.74      0.79      1000\n",
      "           3       0.78      0.62      0.69      1000\n",
      "           4       0.77      0.89      0.82      1000\n",
      "           5       0.80      0.75      0.78      1000\n",
      "           6       0.90      0.87      0.89      1000\n",
      "           7       0.81      0.94      0.87      1000\n",
      "           8       0.92      0.91      0.92      1000\n",
      "           9       0.90      0.90      0.90      1000\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     10000\n",
      "   macro avg       0.85      0.85      0.84     10000\n",
      "weighted avg       0.85      0.85      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NN + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(train_pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8509\n"
     ]
    }
   ],
   "source": [
    "test_pred_labels = classifier.predict(test_pred)\n",
    "\n",
    "print(accuracy_score(y_test,test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[879  10  24  11  13   1   2   6  35  19]\n",
      " [  6 938   0   3   2   1   0   0   8  42]\n",
      " [ 42   4 778  33  60  21  31  20   6   5]\n",
      " [ 14   4  47 690  40 119  35  32   8  11]\n",
      " [ 10   4  24  26 864  20   9  38   5   0]\n",
      " [ 10   7  29 110  30 759  12  36   0   7]\n",
      " [  8   5  27  43  28   8 873   3   3   2]\n",
      " [  5   1  10  20  27  26   1 908   0   2]\n",
      " [ 32  15   3   5   3   1   3   3 916  19]\n",
      " [ 20  49   2   5   1   0   1   4  14 904]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, test_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
